AWSTemplateFormatVersion: '2010-09-09'
Description: 'Install Karpenter using Helm with proper EKS authentication'

Parameters:
  EKSClusterName:
    Type: String
    Description: Name of the EKS cluster
  PrivateSubnets:
    Type: CommaDelimitedList
    Description: Private subnet IDs for Karpenter nodes
  ClusterSecurityGroupId:
    Type: String
    Description: EKS cluster security group ID

Resources:
  # Karpenter Controller IAM Role with OIDC
  KarpenterControllerRole:
    Type: AWS::IAM::Role
    Properties:
      RoleName: !Sub 'KarpenterController-${EKSClusterName}'
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Effect: Allow
            Principal:
              Federated: !Sub 'arn:aws:iam::${AWS::AccountId}:oidc-provider/${OIDCProvider}'
            Action: sts:AssumeRoleWithWebIdentity
            Condition:
              StringEquals:
                !Sub '${OIDCProvider}:sub': 'system:serviceaccount:karpenter:karpenter'
                !Sub '${OIDCProvider}:aud': 'sts.amazonaws.com'
      ManagedPolicyArns:
        - !Ref KarpenterControllerPolicy

  # Get OIDC provider from EKS cluster
  OIDCProvider:
    Type: AWS::CloudFormation::CustomResource
    Properties:
      ServiceToken: !GetAtt OIDCProviderFunction.Arn
      ClusterName: !Ref EKSClusterName

  OIDCProviderFunction:
    Type: AWS::Lambda::Function
    Properties:
      Runtime: python3.9
      Handler: index.handler
      Role: !GetAtt OIDCProviderRole.Arn
      Code:
        ZipFile: |
          import boto3
          import cfnresponse
          
          def handler(event, context):
              try:
                  if event['RequestType'] == 'Create':
                      eks = boto3.client('eks')
                      cluster_name = event['ResourceProperties']['ClusterName']
                      
                      response = eks.describe_cluster(name=cluster_name)
                      oidc_url = response['cluster']['identity']['oidc']['issuer']
                      oidc_provider = oidc_url.replace('https://', '')
                      
                      cfnresponse.send(event, context, cfnresponse.SUCCESS, {}, oidc_provider)
                  else:
                      cfnresponse.send(event, context, cfnresponse.SUCCESS, {})
              except Exception as e:
                  cfnresponse.send(event, context, cfnresponse.FAILED, {'Error': str(e)})

  OIDCProviderRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Effect: Allow
            Principal:
              Service: lambda.amazonaws.com
            Action: sts:AssumeRole
      ManagedPolicyArns:
        - arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole
      Policies:
        - PolicyName: EKSDescribe
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Effect: Allow
                Action: eks:DescribeCluster
                Resource: '*'

  KarpenterControllerPolicy:
    Type: AWS::IAM::ManagedPolicy
    Properties:
      ManagedPolicyName: !Sub 'KarpenterController-${EKSClusterName}'
      PolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Effect: Allow
            Action: '*'
            Resource: '*'

  # Karpenter Node IAM Role
  KarpenterNodeRole:
    Type: AWS::IAM::Role
    Properties:
      RoleName: !Sub 'KarpenterNode-${EKSClusterName}'
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Effect: Allow
            Principal:
              Service: ec2.amazonaws.com
            Action: sts:AssumeRole
      ManagedPolicyArns:
        - arn:aws:iam::aws:policy/AmazonEKSWorkerNodePolicy
        - arn:aws:iam::aws:policy/AmazonEKS_CNI_Policy
        - arn:aws:iam::aws:policy/AmazonEC2ContainerRegistryReadOnly
        - arn:aws:iam::aws:policy/AmazonSSMManagedInstanceCore

  KarpenterNodeInstanceProfile:
    Type: AWS::IAM::InstanceProfile
    Properties:
      InstanceProfileName: !Sub 'KarpenterNode-${EKSClusterName}'
      Roles:
        - !Ref KarpenterNodeRole

  # EKS Pod Identity Association for Karpenter
  KarpenterPodIdentity:
    Type: AWS::EKS::PodIdentityAssociation
    Properties:
      ClusterName: !Ref EKSClusterName
      Namespace: karpenter
      ServiceAccount: karpenter
      RoleArn: !GetAtt KarpenterControllerRole.Arn

  # Helm installation using EKS add-on approach
  KarpenterInstaller:
    Type: AWS::Lambda::Function
    Properties:
      FunctionName: !Sub 'KarpenterHelmInstaller-${EKSClusterName}'
      Runtime: python3.9
      Handler: index.handler
      Role: !GetAtt KarpenterInstallerRole.Arn
      Timeout: 600
      Code:
        ZipFile: |
          import boto3
          import json
          import cfnresponse
          import subprocess
          import os
          import urllib.request
          import stat
          
          def handler(event, context):
              try:
                  if event['RequestType'] == 'Create':
                      cluster_name = event['ResourceProperties']['ClusterName']
                      subnets = event['ResourceProperties']['Subnets']
                      security_group = event['ResourceProperties']['SecurityGroup']
                      region = event['ResourceProperties']['Region']
                      
                      ec2 = boto3.client('ec2', region_name=region)
                      
                      # Tag subnets for Karpenter discovery
                      for subnet in subnets:
                          ec2.create_tags(
                              Resources=[subnet],
                              Tags=[{'Key': 'karpenter.sh/discovery', 'Value': cluster_name}]
                          )
                      
                      # Tag security group for Karpenter discovery
                      ec2.create_tags(
                          Resources=[security_group],
                          Tags=[{'Key': 'karpenter.sh/discovery', 'Value': cluster_name}]
                      )
                      
                      # Download and install kubectl
                      urllib.request.urlretrieve('https://dl.k8s.io/release/v1.28.0/bin/linux/amd64/kubectl', '/tmp/kubectl')
                      os.chmod('/tmp/kubectl', stat.S_IRWXU)
                      
                      # Download and install helm
                      urllib.request.urlretrieve('https://get.helm.sh/helm-v3.13.0-linux-amd64.tar.gz', '/tmp/helm.tar.gz')
                      subprocess.run(['tar', '-xzf', '/tmp/helm.tar.gz', '-C', '/tmp'], check=True)
                      os.chmod('/tmp/linux-amd64/helm', stat.S_IRWXU)
                      
                      # Set environment
                      os.environ['AWS_DEFAULT_REGION'] = region
                      
                      # Update kubeconfig with admin access
                      subprocess.run(['aws', 'eks', 'update-kubeconfig', '--name', cluster_name, '--region', region], check=True)
                      
                      # Install Karpenter using Helm
                      subprocess.run([
                          '/tmp/linux-amd64/helm', 'upgrade', '--install', 'karpenter',
                          'oci://public.ecr.aws/karpenter/karpenter',
                          '--version', '1.0.1',
                          '--namespace', 'karpenter',
                          '--create-namespace',
                          '--set', f'settings.clusterName={cluster_name}',
                          '--set', 'serviceAccount.create=false',
                          '--wait'
                      ], check=True)
                      
                      cfnresponse.send(event, context, cfnresponse.SUCCESS, {
                          'Message': 'Karpenter v1.0.1 installed successfully via Helm'
                      })
                  else:
                      cfnresponse.send(event, context, cfnresponse.SUCCESS, {'Message': 'No action required'})
              except Exception as e:
                  print('Error: ' + str(e))
                  cfnresponse.send(event, context, cfnresponse.FAILED, {'Error': str(e)})

  KarpenterInstallerRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Effect: Allow
            Principal:
              Service: lambda.amazonaws.com
            Action: sts:AssumeRole
      ManagedPolicyArns:
        - arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole
      Policies:
        - PolicyName: KarpenterHelmInstallPolicy
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Effect: Allow
                Action: '*'
                Resource: '*'

  # Custom resource to trigger installation
  KarpenterSetup:
    Type: AWS::CloudFormation::CustomResource
    DependsOn: KarpenterPodIdentity
    Properties:
      ServiceToken: !GetAtt KarpenterInstaller.Arn
      ClusterName: !Ref EKSClusterName
      Subnets: !Ref PrivateSubnets
      SecurityGroup: !Ref ClusterSecurityGroupId
      Region: !Ref AWS::Region

Outputs:
  KarpenterControllerRoleArn:
    Description: Karpenter Controller Role ARN
    Value: !GetAtt KarpenterControllerRole.Arn
  KarpenterNodeRoleArn:
    Description: Karpenter Node Role ARN  
    Value: !GetAtt KarpenterNodeRole.Arn
  CodeBuildRoleArn:
    Description: CodeBuild Role ARN for EKS access
    Value: !GetAtt KarpenterInstallerRole.Arn
  KarpenterSetupMessage:
    Description: Karpenter installation status
    Value: !GetAtt KarpenterSetup.Message